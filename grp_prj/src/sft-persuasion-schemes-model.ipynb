{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "MPATH = \"roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MPATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the data modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building the Utterance Labels: 100%|██████████| 1534/1534 [00:00<00:00, 66691.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from datautils import PersuationSchemeDataModule, PersuationSchemeBatcher\n",
    "\n",
    "\n",
    "DPATH = r\"..\\data\\persuasionforgood_corpus\"\n",
    "\n",
    "batcher = PersuationSchemeBatcher(tokenizer)\n",
    "dm = PersuationSchemeDataModule(\n",
    "    DPATH,\n",
    "    batcher=batcher,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# To harvest the id2label dict\n",
    "dm.setup('test')\n",
    "id2label = dm.test_dataset.id2label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded fresh model\n"
     ]
    }
   ],
   "source": [
    "from modelling import PersuasionSchemeClassifier\n",
    "\n",
    "\n",
    "SAVE_PATH = f\"../models/persuasion-schemes-classifier\"\n",
    "CKPT = \"\"\n",
    "\n",
    "model = PersuasionSchemeClassifier(\n",
    "    MPATH,\n",
    "    id2label=id2label\n",
    ")\n",
    "print(\"Loaded fresh model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/persuasion-schemes-classifier\\\\tokenizer_config.json',\n",
       " '../models/persuasion-schemes-classifier\\\\special_tokens_map.json',\n",
       " '../models/persuasion-schemes-classifier\\\\vocab.json',\n",
       " '../models/persuasion-schemes-classifier\\\\merges.txt',\n",
       " '../models/persuasion-schemes-classifier\\\\added_tokens.json',\n",
       " '../models/persuasion-schemes-classifier\\\\tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(SAVE_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import(\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    RichModelSummary\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    SAVE_PATH,\n",
    "    filename=f'epoch-{{epoch}}-{{val_loss:.2f}}',\n",
    "    monitor='val_overall_f1_score',\n",
    "    save_weights_only=True,\n",
    "    mode='max'\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_overall_f1_score\",\n",
    "    min_delta=1e-4, patience=8,\n",
    "    verbose=False,\n",
    "    mode=\"max\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "d:\\envs\\expts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "Building the Utterance Labels: 100%|██████████| 3451/3451 [00:00<00:00, 67668.09it/s]\n",
      "Building the Utterance Labels: 100%|██████████| 1151/1151 [00:00<00:00, 67696.55it/s]\n",
      "d:\\envs\\expts\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:612: UserWarning: Checkpoint directory D:\\repos\\cse546-rl-assignments\\grp_prj\\models\\persuasion-schemes-classifier exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name           </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ seq_classifier │ RobertaForSequenceClassification │  124 M │\n",
       "└───┴────────────────┴──────────────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName          \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ seq_classifier │ RobertaForSequenceClassification │  124 M │\n",
       "└───┴────────────────┴──────────────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 124 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 124 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 498                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 124 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 124 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 498                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161994ca206f4127959213ccf5b2622e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\envs\\expts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "d:\\envs\\expts\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a1c2d6c3d744d594c3a9e71e22f0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0569f71051f431293dc2ada0fc2d203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12992a8b2be4628ab01ff1168a993f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc23cef32fc342638072e3fd34a90db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0faa2ea18fd419693b1d04e44336962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6fab67aaf74abbab282f1f215f429c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4e11cffe264209b7d4c1bc523dc224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de07f1ec1b8c48d9b61b4f0d38bbbcf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1fc48062fd491cabe332e37bc309c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0bfde3a22245419e7eb9a17f899a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4366a05ac1e5486fa7483c2e1d1bf963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cd8ba8b49649a1b7482ca3374f40a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8a98cfd25c4a5c974bf842918cd0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05cb3f60169c42c388b41acce1ba1e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a01d67e9254187a954363e2a382730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9baf7fbb8e0420397eeb60f340642e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b558b98b54e4862a205d662af99423f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b981dfdce2094f8e8170b525acc35545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42ac14e3d1c43668b2d94382f1a0774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b54c430c59d44ccb63ed5e9351bdc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc323b1cd30461cac4a934f4f8cb1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8b807117d24a66958e50ea1b3e3b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62399938864041d2a2e3ceb7fdc73390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c1f0e6aa5a4953a7b646f55c758b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d013d6114ef44456bc56a769e721c409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7d51b23a394e459e689a45e0c4213e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999936cc27f940e6b1d6047a2cb7b9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78cb1e41b83c40bd8e208fc773f1278b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=-1,\n",
    "    deterministic=True,\n",
    "    accumulate_grad_batches=2,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback, RichModelSummary()],\n",
    "    accelerator='gpu',\n",
    "    log_every_n_steps=16\n",
    ")\n",
    "\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = PersuasionSchemeClassifier.load_from_checkpoint(r'D:\\repos\\cse546-rl-assignments\\grp_prj\\models\\persuasion-schemes-classifier\\epoch-epoch=18-val_loss=0.56.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building the Utterance Labels: 100%|██████████| 1534/1534 [00:00<00:00, 61369.72it/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd035f4f639847e6bde5fa236853ed13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">              Runningstage.testing metric               </span>┃<span style=\"font-weight: bold\">                      DataLoader 0                      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_granular_f1_score_acknowledgement         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.4965677857398987                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_granular_f1_score_agree-donation          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.4566958248615265                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_granular_f1_score_ask-donate-more         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.1794871836900711                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_granular_f1_score_ask-donation-amount       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.5679518580436707                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_granular_f1_score_ask-donation-procedure      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.43523934483528137                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_granular_f1_score_ask-not-donate-reason      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                          0.0                           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_granular_f1_score_ask-org-info           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.6838791370391846                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_granular_f1_score_ask-persuader-donation-intenti… </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.23502826690673828                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">             test_granular_f1_score_closing             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.5285803079605103                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_granular_f1_score_comment-partner         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.027813995257019997                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_granular_f1_score_confirm-donation         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.27833864092826843                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_granular_f1_score_credibility-appeal        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                    0.72699373960495                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_granular_f1_score_disagree-donation        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.2967405319213867                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_granular_f1_score_disagree-donation-more      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                          0.0                           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_granular_f1_score_donation-information       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.6261316537857056                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_granular_f1_score_emotion-appeal          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.5566400289535522                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_granular_f1_score_foot-in-the-door         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.4109848737716675                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            test_granular_f1_score_greeting             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.901367723941803                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_granular_f1_score_logical-appeal          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.4560949504375458                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_granular_f1_score_negative-reaction-to-donation  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.3249022364616394                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_granular_f1_score_negative-to-inquiry       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.4736429452896118                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_granular_f1_score_neutral-reaction-to-donation   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.027813995257019997                  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_granular_f1_score_neutral-to-inquiry        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.1126466765999794                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            test_granular_f1_score_off-task             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.1296330839395523                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">              test_granular_f1_score_other              </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.3900463879108429                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test_granular_f1_score_personal-related-inquiry     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.5120800137519836                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_granular_f1_score_personal-story          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.16410258412361145                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_granular_f1_score_positive-reaction-to-donation  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.47991541028022766                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_granular_f1_score_positive-to-inquiry       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.4047980010509491                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           test_granular_f1_score_praise-user           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.35108548402786255                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_granular_f1_score_proposition-of-donation     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.5613510608673096                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_granular_f1_score_provide-donation-amount     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.5850540995597839                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_granular_f1_score_self-modeling          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.32721778750419617                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_granular_f1_score_source-related-inquiry      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.710270881652832                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_granular_f1_score_task-related-inquiry       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.40407130122184753                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">              test_granular_f1_score_thank              </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.7790353298187256                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_granular_f1_score_you-are-welcome         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                  0.31986093521118164                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                        val_loss                        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                    0.55733323097229                    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                   val_macro_f1_score                   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.4032990634441376                   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">                  val_overall_f1_score                  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">                   0.5477519035339355                   </span>│\n",
       "└────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m             Runningstage.testing metric              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                     DataLoader 0                     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_granular_f1_score_acknowledgement        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.4965677857398987                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_granular_f1_score_agree-donation         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.4566958248615265                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_granular_f1_score_ask-donate-more        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.1794871836900711                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_granular_f1_score_ask-donation-amount      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.5679518580436707                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_granular_f1_score_ask-donation-procedure     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.43523934483528137                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_granular_f1_score_ask-not-donate-reason     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                         0.0                          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_granular_f1_score_ask-org-info          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.6838791370391846                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_granular_f1_score_ask-persuader-donation-intenti…\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.23502826690673828                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m            test_granular_f1_score_closing            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.5285803079605103                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_granular_f1_score_comment-partner        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.027813995257019997                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_granular_f1_score_confirm-donation        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.27833864092826843                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_granular_f1_score_credibility-appeal       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                   0.72699373960495                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_granular_f1_score_disagree-donation       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.2967405319213867                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_granular_f1_score_disagree-donation-more     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                         0.0                          \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_granular_f1_score_donation-information      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.6261316537857056                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_granular_f1_score_emotion-appeal         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.5566400289535522                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_granular_f1_score_foot-in-the-door        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.4109848737716675                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m           test_granular_f1_score_greeting            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.901367723941803                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_granular_f1_score_logical-appeal         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.4560949504375458                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_granular_f1_score_negative-reaction-to-donation \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.3249022364616394                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_granular_f1_score_negative-to-inquiry      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.4736429452896118                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_granular_f1_score_neutral-reaction-to-donation  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.027813995257019997                 \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_granular_f1_score_neutral-to-inquiry       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.1126466765999794                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m           test_granular_f1_score_off-task            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.1296330839395523                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m             test_granular_f1_score_other             \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.3900463879108429                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test_granular_f1_score_personal-related-inquiry    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.5120800137519836                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_granular_f1_score_personal-story         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.16410258412361145                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_granular_f1_score_positive-reaction-to-donation \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.47991541028022766                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_granular_f1_score_positive-to-inquiry      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.4047980010509491                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          test_granular_f1_score_praise-user          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.35108548402786255                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_granular_f1_score_proposition-of-donation    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.5613510608673096                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_granular_f1_score_provide-donation-amount    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.5850540995597839                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_granular_f1_score_self-modeling         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.32721778750419617                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_granular_f1_score_source-related-inquiry     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.710270881652832                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_granular_f1_score_task-related-inquiry      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.40407130122184753                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m             test_granular_f1_score_thank             \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.7790353298187256                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_granular_f1_score_you-are-welcome        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                 0.31986093521118164                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                       val_loss                       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                   0.55733323097229                   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                  val_macro_f1_score                  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.4032990634441376                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m                 val_overall_f1_score                 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m                  0.5477519035339355                  \u001b[0m\u001b[35m \u001b[0m│\n",
       "└────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    trainer.test(model, dm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1f2d826c9546958484ec8d6b7a564b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ef7a62cb8b450aa4cecbc974e0dc4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/nasheed/rl-grp-prj-per-cls/commit/83617b5381eef42d71b06a2706f1ea3e900f3f19', commit_message='Upload RobertaForSequenceClassification', commit_description='', oid='83617b5381eef42d71b06a2706f1ea3e900f3f19', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.seq_classifier.push_to_hub('nasheed/rl-grp-prj-per-cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.push_to_hub('nasheed/rl-grp-prj-per-cls')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
